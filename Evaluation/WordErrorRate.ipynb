{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook evaluates the post-corrected text using word error rates. We treat the text from Ash and NCKP as ground truth. This evaluation mainly focuses on the capability of neuspell to correct individual words. We get the samples by:\n",
    "    * Find all terms with High quality and low quality, and moderate qualit in Edition 1 1771, Edition 7 1842.\n",
    "    * From these terms, if the number of words of a term are the same between high quality text, and low quality one, then this term will be added as a sample.\n",
    "    * All texts from the sample will be normalised (lowercase, remove punctuation).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the samples\n",
    "# Treat the text from Ash and NCKP as ground truth\n",
    "# Find all terms with High quality and low quality, and moderate qualit in Edition 1 1771, Edition 7 1842.\n",
    "# From these terms, if the number of words of a term are the same between high quality text, and low quality one, then this term will be added as a sample."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from rdflib import Namespace\n",
    "\n",
    "hto = Namespace(\"https://w3id.org/hto#\")\n",
    "\n",
    "sparql = SPARQLWrapper(\n",
    "    \"http://query.frances-ai.com/hto\"\n",
    ")\n",
    "sparql.setReturnFormat(JSON)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "NON_AZ_REGEXP = re.compile(\"[^a-z]\")\n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Normalize a word by converting it to lower-case and removing all\n",
    "    characters that are not 'a',...,'z'.\n",
    "\n",
    "    :param word: Word to normalize\n",
    "    :type word: str or unicode\n",
    "    :return: normalized word\n",
    "    :rtype word: str or unicode\n",
    "    \"\"\"\n",
    "    return re.sub(NON_AZ_REGEXP, '', word.lower())\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    all_words = text.split()\n",
    "    all_normalised_words = []\n",
    "    for word in all_words:\n",
    "        all_normalised_words.append(normalize(word))\n",
    "    return ' '.join(all_normalised_words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def get_samples():\n",
    "    sample_info_list = []\n",
    "    sparql.setQuery(\"\"\"\n",
    "    PREFIX hto: <https://w3id.org/hto#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?term_uri ?mq_text ?hq_text ?lq_text WHERE {\n",
    "        ?term_uri a ?term_type;\n",
    "            hto:name ?name;\n",
    "            hto:startsAtPage ?startPage;\n",
    "            hto:hasOriginalDescription ?hq_desc, ?lq_desc, ?mq_desc.\n",
    "        ?hq_desc hto:text ?hq_text;\n",
    "            hto:hasTextQuality hto:High.\n",
    "  \t\t?mq_desc hto:text ?mq_text;\n",
    "            hto:hasTextQuality hto:Moderate.\n",
    "  \t\t?lq_desc hto:text ?lq_text;\n",
    "            hto:hasTextQuality hto:Low.\n",
    "  \t\t# Calculate word count for high-quality description\n",
    "    \tBIND (STRLEN(REPLACE(?hq_text, \"\\\\\\\\S\", \" \")) AS ?high_length)\n",
    "\n",
    "    \t# Calculate word count for low-quality description\n",
    "    \tBIND (STRLEN(REPLACE(?lq_text, \"\\\\\\\\S\", \" \")) AS ?low_length)\n",
    "      \t# Ensure that the word count matches between high and low-quality descriptions\n",
    "        FILTER (?term_type = hto:ArticleTermRecord || ?term_type = hto:TopicTermRecord)\n",
    "  \t\t# Ensure that the word count matches between high and low-quality descriptions\n",
    "    \tFILTER (?high_length = ?low_length)\n",
    "        ?vol a hto:Volume;\n",
    "            hto:hadMember ?startPage.\n",
    "        ?edition a hto:Edition;\n",
    "            hto:hadMember ?vol;\n",
    "            hto:yearPublished ?year_published.\n",
    "        FILTER (?year_published = 1771 || ?year_published = 1842)\n",
    "        }\n",
    "    \"\"\"\n",
    "                    )\n",
    "\n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "        for r in ret[\"results\"][\"bindings\"]:\n",
    "            sample_info_list.append({\n",
    "                \"term_uri\": r[\"term_uri\"][\"value\"],\n",
    "                \"hq_text\": normalize_text(r[\"hq_text\"][\"value\"]),\n",
    "                \"mq_text\": normalize_text(r[\"mq_text\"][\"value\"]),\n",
    "                \"lq_text\": normalize_text(r[\"lq_text\"][\"value\"])\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return sample_info_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "samples = get_samples()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "1923"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "\n",
    "\n",
    "def calculate_wer(high_quality_text: str, low_quality_text: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Word Error Rate (WER) between high-quality and low-quality text.\n",
    "\n",
    "    Args:\n",
    "    - high_quality_text: The ground truth high-quality text.\n",
    "    - low_quality_text: The transcription to compare against the ground truth.\n",
    "\n",
    "    Returns:\n",
    "    - The Word Error Rate (WER) as a floating-point number.\n",
    "    \"\"\"\n",
    "    # Calculate the Word Error Rate using jiwer\n",
    "    error_rate = wer(high_quality_text, low_quality_text)\n",
    "\n",
    "    return error_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    lq_wer = calculate_wer(sample[\"hq_text\"], sample[\"lq_text\"])\n",
    "    mq_wer = calculate_wer(sample[\"hq_text\"], sample[\"mq_text\"])\n",
    "    sample[\"lq_wer\"] = lq_wer\n",
    "    sample[\"mq_wer\"] = mq_wer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "improved_terms = [sample for sample in samples if sample[\"mq_wer\"] < sample[\"lq_wer\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "wrongly_correct_terms = [sample for sample in samples if sample[\"mq_wer\"] > sample[\"lq_wer\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "788"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrongly_correct_terms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "126"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(improved_terms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of terms which have been successfully corrected: 126, the success rate: 0.0655226209048362\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of terms which have been successfully corrected: {len(improved_terms)}, the success rate: {len(improved_terms) / len(samples)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of terms which have been wrongly corrected: 788, the fail rate: 0.40977639105564223\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of terms which have been wrongly corrected: {len(wrongly_correct_terms)}, the fail rate: {len(wrongly_correct_terms) / len(samples)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
